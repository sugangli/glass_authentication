\section{Concluding Remarks and Future Direction}
\label{sec:conc}
As wearable devices are increasingly weaved into our everyday life, providing security to the data acquired by or accessed through these devices becomes critically important. In this study, we have developed a user authentication system that uses head-movement patterns for direct
authentication to a wearable device. Compared to existing authentication solutions, the proposed solution delivers accurate authentication, is robust against imitation attacks, incurs low processing delays, and offers great convenience to users. 

%We developed a light-weight approach that
%infers head-movements of users in response to music and generates signatures
%that are unique to every user.
%Our technique specifically uses the dynamic time-warping (DTW) tool to
%generate a head-movement feature that contains the mean and standard
%deviation of the DTW score of each user, determined over a multiple-user data
%set. The matching is conducted based on a thresholding scheme.
%Experimental observations revealed that the head-movement signatures generated
%using the dynamic time-warping tool, in response to the same music track, were
%consistent in typical stationary environments such as user sitting or
%standing at one location while attempting to authenticate. We leveraged the
%consistency in the head-movement signatures to develop two classification
%algorithms, based on machine learning and adaptive thresholding, to
%efficiently and accurately label user signatures.
Through an extensive evaluation that involves 67 users, we observe that the
average true acceptance rate of our approach is at 95.57$\%$ and the false
acceptance rates at 4.43$\%$. We also observe that even simple head-movement patterns only allow less then 3\% of the imitation attacks to succeed. We have also implemented an app on Google Glass, and measured the end-to-end processing delay of less than 2 seconds for a 10-second data sample. As a result, we believe it is realistic for the proposed authentication system to be executed on resource-constrained devices such as smart-glass. We further believe the proposed method can help enable wider deployment of wearable devices and apps in our life. Towards this goal, in our future work, we will focus on how to make the head-movement based user authentication approach more reliable in real-world settings.

%We have also optimized our algorithms to
%minimize the processing latencies and power consumption, making them suitable
%for wearable devices.
%The multi-user data sets were validated and verified during the
%course of our evaluations and will be released for public use in near future.

\iffalse
In this paper, we present the design, implementation and evaluation
of Headbanger, a head gesture based authentication system.
Headbanger generates a signature from user's head-movements in
response to short duration of audio track with fast beats, and uses
this signature as the behavioral biometric for authentication.
Through extensive experiments on the prototype on Google Glass
involving ?? users, we demonstrated that Headbander can achieve **\%
accuracy and thus with proper audio stimuli, head-movement alone
will be reasonably sufficient to serve a effective behavioral
biometric for authentication. We believe this work will be the basis
for using audio catalyst to enrich more useful human contextual
applications.
\fi 