\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{googleglass,smartwatch,fitbit}
\citation{hoyle2015sensitive,hoyle2014privacy,jana2013scanner}
\citation{fitbit,smartwatch}
\citation{googleglass}
\citation{fitbit}
\citation{rahman2014bodybeat,cornelius2014wearable,stevenage1999visual,okumura2006study,monrose2000keystroke,jorgensen2011mouse,bo2013silentsense,de2012touch}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{I}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Illustration of Headbanger. The head-worn device authenticates the users based on signatures generated from head-movement patterns. These patterns are created in response to an audio snapshot played on the device.}}{1}{figure.1}}
\newlabel{fig:headbanger-illustrate}{{1}{1}{Illustration of Headbanger. The head-worn device authenticates the users based on signatures generated from head-movement patterns. These patterns are created in response to an audio snapshot played on the device}{figure.1}{}}
\citation{jain2004introduction,o2003comparing,yampolskiy2007motor}
\citation{collins2002silhouette}
\citation{ailisto2006soft}
\citation{nymi}
\citation{stevenage1999visual}
\citation{okumura2006study}
\citation{monrose2000keystroke}
\citation{jorgensen2011mouse}
\citation{bo2013silentsense,de2012touch}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{2}{section.2}}
\newlabel{sec:background}{{II}{2}{Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-A}}Wearable Device Authentication}{2}{subsection.2.1}}
\citation{jain2004introduction}
\citation{zentner2010rhythmic}
\citation{eye blink}
\citation{tap beat}
\citation{cite dtw}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {II-B}}Head-movement as a Biometric}{3}{subsection.2.2}}
\newlabel{subsec:headmovements}{{\unhbox \voidb@x \hbox {II-B}}{3}{Head-movement as a Biometric}{subsection.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Feature}{3}{section.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces  Wave Amplitude and Width Boxplot}}{3}{figure.3}}
\newlabel{fig:width_amp}{{3}{3}{Wave Amplitude and Width Boxplot}{figure.3}{}}
\citation{googleglass}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  These plots show the raw accelerometer data in the time domain for five different users when they move their head in response to the same music track wearing the same Google glass. The plots indicate that different users' head movement patterns appear distinctive from each other. The three users wore a Google Glass (in turns) and listened to a 10 second audio snapshot of a pop song.}}{4}{figure.2}}
\newlabel{fig:raw}{{2}{4}{These plots show the raw accelerometer data in the time domain for five different users when they move their head in response to the same music track wearing the same Google glass. The plots indicate that different users' head movement patterns appear distinctive from each other. The three users wore a Google Glass (in turns) and listened to a 10 second audio snapshot of a pop song}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  The similarity score is computed over N (N = 20) sample data for each subject, and 28 subjects in total. For each column, a red dot represents the average similarity score of that subject's own SRT, i.e., each of his sample data compared with the other N-1 SRTs from him, hence we have the average similarity score over all these comparison. Similarly, a blue dot on the same column represents the similarity score of that subject's SRTs compares with another subject's SRTs.}}{4}{figure.4}}
\newlabel{fig:distance}{{4}{4}{The similarity score is computed over N (N = 20) sample data for each subject, and 28 subjects in total. For each column, a red dot represents the average similarity score of that subject's own SRT, i.e., each of his sample data compared with the other N-1 SRTs from him, hence we have the average similarity score over all these comparison. Similarly, a blue dot on the same column represents the similarity score of that subject's SRTs compares with another subject's SRTs}{figure.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Headbanger System Design}{4}{section.4}}
\newlabel{sec:design}{{IV}{4}{Headbanger System Design}{section.4}{}}
\citation{dtw}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces  Accelerometer data from three users, in the frequency domain. The data show that the spectrum is significantly concentrated within 5Hz for all three users.}}{5}{figure.6}}
\newlabel{fig:raw_freq}{{6}{5}{Accelerometer data from three users, in the frequency domain. The data show that the spectrum is significantly concentrated within 5Hz for all three users}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces {\em  Headbanger}\nobreakspace  {}system design flow. The online authentication phase of {\em  Headbanger}\nobreakspace  {}consists of the following steps: (1) sensor data collection in which we collect accelerometer data while users move their head as a response to an audio track played on the glass, (2) filtering in which we apply a Butterworth filtering to smoothen the sensor data for subsequent processing, (3) signature generation in which we calculate the dynamic time warping (DTW) distances between two accelerometer samples as the signature, and (4) classification in which we adopt an adaptive thresholding mechanism to classify the user's head movement, whose result will be used as the authentication result.}}{5}{figure.5}}
\newlabel{fig:sysarch}{{5}{5}{\systemname ~system design flow. The online authentication phase of \systemname ~consists of the following steps: (1) sensor data collection in which we collect accelerometer data while users move their head as a response to an audio track played on the glass, (2) filtering in which we apply a Butterworth filtering to smoothen the sensor data for subsequent processing, (3) signature generation in which we calculate the dynamic time warping (DTW) distances between two accelerometer samples as the signature, and (4) classification in which we adopt an adaptive thresholding mechanism to classify the user's head movement, whose result will be used as the authentication result}{figure.5}{}}
\citation{beats}
\citation{challis1983design}
\citation{dtw}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Sensor Data Collection}{6}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Filtering}{6}{subsection.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-C}}Signature generation}{6}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-D}}Classification}{6}{subsection.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Filtered accelerometer signals. Applied Butterworth filter of order 2 and cut-off frequency 10Hz. }}{7}{figure.7}}
\newlabel{fig:filteredacc}{{7}{7}{Filtered accelerometer signals. Applied Butterworth filter of order 2 and cut-off frequency 10Hz}{figure.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation}{7}{section.5}}
\newlabel{sec:results}{{V}{7}{Evaluation}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Method}{7}{subsection.5.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {V-A}0a}Participants}{7}{paragraph.5.1.0.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {V-A}0b}Procedure}{7}{paragraph.5.1.0.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Accuracy}{7}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Evaluation of impact of music cue duration on TPR and FAR in Top-1 scheme ($K = 1$). A 10 sec music snapshot is trimmed into music cues of 10 sec, 6 sec and 5 sec correspondingly.The variable here is $n$. Each (TPR, FAR) data point in the curve corresponds to a different value of $n$}}{8}{figure.8}}
\newlabel{fig:roc-top1}{{8}{8}{Evaluation of impact of music cue duration on TPR and FAR in Top-1 scheme ($K = 1$). A 10 sec music snapshot is trimmed into music cues of 10 sec, 6 sec and 5 sec correspondingly.The variable here is $n$. Each (TPR, FAR) data point in the curve corresponds to a different value of $n$}{figure.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Evaluation of impact of music cue duration on TPR and FAR in Top-3 voting scheme ($K = 3$). A 10 sec music snapshot is trimmed into music cues of 10 sec, 6 sec and 5 sec correspondingly.The variable here is $n$. Each (TPR, FAR) data point in the curve corresponds to a different value of $n$}}{8}{figure.9}}
\newlabel{fig:roc-top3}{{9}{8}{Evaluation of impact of music cue duration on TPR and FAR in Top-3 voting scheme ($K = 3$). A 10 sec music snapshot is trimmed into music cues of 10 sec, 6 sec and 5 sec correspondingly.The variable here is $n$. Each (TPR, FAR) data point in the curve corresponds to a different value of $n$}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Comparison of EER for different music lengths (10 sec, 6 sec and 5 sec) with a fixed n value of 2.7}}{8}{figure.10}}
\newlabel{fig:eer-length}{{10}{8}{Comparison of EER for different music lengths (10 sec, 6 sec and 5 sec) with a fixed n value of 2.7}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces  Evaluation of impact of different distance metric (DTW, cosine distance, and Correlation). Although DTW is relatively computing-intensive, ROC curve indicates that DTW provides a large enhancement over the other two metrics. }}{8}{figure.11}}
\newlabel{fig:roc_dtw_cos_cor}{{11}{8}{Evaluation of impact of different distance metric (DTW, cosine distance, and Correlation). Although DTW is relatively computing-intensive, ROC curve indicates that DTW provides a large enhancement over the other two metrics}{figure.11}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {V-B}0c}Impact of similarity algorithm}{8}{paragraph.5.2.0.3}}
\citation{von2013patterns}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces  Evaluation of impact of different sampling rate shows that the highest sampling rate 200 Hz gives the best resutlt. However, the sampling rate determines computational effort for the smart device, which could be significant in terms of response time.}}{9}{figure.12}}
\newlabel{fig:roc_dtw_diff_freq}{{12}{9}{Evaluation of impact of different sampling rate shows that the highest sampling rate 200 Hz gives the best resutlt. However, the sampling rate determines computational effort for the smart device, which could be significant in terms of response time}{figure.12}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {V-B}0d}Impact of music cue duration and $K$ value}{9}{paragraph.5.2.0.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Comparison of EER for different training sample sizes (30, 20 and 10) with fixed n value of 2.7}}{9}{figure.13}}
\newlabel{fig:eer-size}{{13}{9}{Comparison of EER for different training sample sizes (30, 20 and 10) with fixed n value of 2.7}{figure.13}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {\unhbox \voidb@x \hbox {V-B}0e}Impact of Training set size}{9}{paragraph.5.2.0.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Is it Secured?}{9}{subsection.5.3}}
\citation{von2013patterns,egelman2014you}
\citation{salvador2007toward}
\citation{ha2014towards}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces My caption}}{10}{table.1}}
\newlabel{my-label}{{I}{10}{My caption}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Software modules of {\em  Headbanger}\nobreakspace  {}implementation}}{10}{figure.14}}
\newlabel{fig:glass-softwarearch}{{14}{10}{Software modules of \systemname ~implementation}{figure.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Headbanger Google Glass App Implementation}{10}{subsection.5.4}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces  Measured response time of {\em  Headbanger}\nobreakspace  {}app implementation on Google Glass with different music cue durations and for $K = 1$. The response time reported here is an average over 20 trials.}}{10}{table.2}}
\newlabel{tab:glass}{{II}{10}{Measured response time of \systemname ~app implementation on Google Glass with different music cue durations and for $K = 1$. The response time reported here is an average over 20 trials}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {\unhbox \voidb@x \hbox {V-D}1}Response time}{10}{table.2}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Discussion}{10}{section.6}}
\newlabel{sec:disc}{{VI}{10}{Discussion}{section.6}{}}
\citation{likamwa2014draining}
\citation{hernandezbioglass,nymi}
\citation{harwin1990analysis}
\citation{westeyn2004recognizing}
\citation{ishimaru2014blink}
\citation{ishimaru2014blink}
\citation{ishimaru2014blink}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Power consumption on Google Glass of components relevant to {\em  Headbanger}. The CPU (running at maximum frequency) power consumption includes that of the heads-up display screen being ON as well. Duration marks the time for which component was ON during the a 10 sec music cue length trial}}{11}{table.3}}
\newlabel{tab:pow}{{III}{11}{Power consumption on Google Glass of components relevant to \systemname . The CPU (running at maximum frequency) power consumption includes that of the heads-up display screen being ON as well. Duration marks the time for which component was ON during the a 10 sec music cue length trial}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-A}}Power consumption}{11}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-B}}Is this secure?}{11}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-C}}Multi-Modality}{11}{subsection.6.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {VI-D}}Large Scale User Study}{11}{subsection.6.4}}
\@writefile{toc}{\contentsline {section}{\numberline {VII}Related Work}{11}{section.7}}
\newlabel{sec:related}{{VII}{11}{Related Work}{section.7}{}}
\citation{kjeldsen2001head,hernandezbioglass}
\citation{kjeldsen2001head}
\citation{hernandezbioglass}
\citation{likamwa2014draining}
\citation{ailisto2005identifying}
\citation{gafurov2007gait}
\citation{okumura2006study,gafurov2008arm}
\citation{gafurov2006biometric}
\citation{gafurov2011user}
\citation{sae2012biometric}
\citation{frank2013touchalytics,cai2013mobile,feng2014tips}
\citation{feng2014tips}
\citation{reynolds2000speaker}
\citation{bowyer2006survey}
\citation{biddle2012graphical}
\citation{sherman2014user}
\citation{jain1997identity}
\bibstyle{abbrv}
\bibdata{sugang}
\bibcite{fitbit}{1}
\bibcite{googleglass}{2}
\bibcite{nymi}{3}
\bibcite{smartwatch}{4}
\bibcite{ailisto2006soft}{5}
\bibcite{ailisto2005identifying}{6}
\bibcite{dtw}{7}
\bibcite{biddle2012graphical}{8}
\bibcite{bo2013silentsense}{9}
\bibcite{bowyer2006survey}{10}
\bibcite{cai2013mobile}{11}
\bibcite{challis1983design}{12}
\bibcite{collins2002silhouette}{13}
\bibcite{cornelius2014wearable}{14}
\bibcite{de2012touch}{15}
\bibcite{egelman2014you}{16}
\bibcite{feng2014tips}{17}
\@writefile{toc}{\contentsline {section}{\numberline {VIII}Concluding Remarks}{12}{section.8}}
\newlabel{sec:conc}{{VIII}{12}{Concluding Remarks}{section.8}{}}
\@writefile{toc}{\contentsline {section}{References}{12}{section*.1}}
\bibcite{frank2013touchalytics}{18}
\bibcite{gafurov2011user}{19}
\bibcite{gafurov2006biometric}{20}
\bibcite{gafurov2007gait}{21}
\bibcite{gafurov2008arm}{22}
\bibcite{ha2014towards}{23}
\bibcite{harwin1990analysis}{24}
\bibcite{hernandezbioglass}{25}
\bibcite{hoyle2015sensitive}{26}
\bibcite{hoyle2014privacy}{27}
\bibcite{ishimaru2014blink}{28}
\bibcite{jain1997identity}{29}
\bibcite{jain2004introduction}{30}
\bibcite{jana2013scanner}{31}
\bibcite{jorgensen2011mouse}{32}
\bibcite{kjeldsen2001head}{33}
\bibcite{likamwa2014draining}{34}
\bibcite{beats}{35}
\bibcite{monrose2000keystroke}{36}
\bibcite{o2003comparing}{37}
\bibcite{okumura2006study}{38}
\bibcite{rahman2014bodybeat}{39}
\bibcite{reynolds2000speaker}{40}
\bibcite{sae2012biometric}{41}
\bibcite{salvador2007toward}{42}
\bibcite{sherman2014user}{43}
\bibcite{stevenage1999visual}{44}
\bibcite{von2013patterns}{45}
\bibcite{westeyn2004recognizing}{46}
\bibcite{yampolskiy2007motor}{47}
\bibcite{zentner2010rhythmic}{48}
