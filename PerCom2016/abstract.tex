\begin{abstract}
In this paper, we present the design, implementation and evaluation of a user authentication system, {\em Headbanger}, for smart head-worn devices, through monitoring the user's unique head-movement patterns in response to an external audio stimulus. Compared to today's solutions, which primarily rely on indirect authentication mechanisms via the user's smartphone, thus cumbersome and susceptible to adversary intrusions, the proposed head-movement based authentication provides an accurate, robust, light-weight and convenient solution.% At the same time,  biometric solutions, on the other hand, are subject to the availability of the specific sensors in the wearable unit.

Through extensive experimental evaluation with 95 participants, we show
that our mechanism can accurately authenticate users with an average true acceptance rate of 95.57\% while keeping the average false acceptance rate of 4.43\%. We also show that even simple head-movement patterns are robust against imitation attacks. Finally, we demonstrate our authentication algorithm is rather light-weight: the overall processing latency on Google Glass is around 1.9 seconds.




%Using a head-worn personal imaging device as a running example and

\end{abstract}

%The recent years have seen a significant growth in popularity of
%smart wearable devices. This growth can be attributed to the advances in
%hardware miniaturization technology as well as economically affordable
%and energy efficient sensing and computing. While size, energy and cost
%constraints remain key motives for improvements in wearable computers'
%design, the aspect of user authentication has received relatively less
%attention. Wearable devices often collect and store sensitive data about
%users, and thus there is an obvious need to authenticate the right user to the
%device. 