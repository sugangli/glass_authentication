\relax 
\citation{mann1997wearable}
\citation{googleglass}
\citation{smartwatch}
\citation{fitbit}
\citation{fitbit}
\citation{smartwatch}
\citation{googleglass}
\citation{fitbit}
\citation{rahman2014bodybeat}
\citation{cornelius2014wearable}
\citation{stevenage1999visual}
\citation{okumura2006study}
\citation{monrose2000keystroke}
\citation{jorgensen2011mouse}
\citation{bo2013silentsense}
\citation{de2012touch}
\citation{jain2004introduction}
\citation{o2003comparing}
\citation{yampolskiy2007motor}
\citation{collins2002silhouette}
\citation{ailisto2006soft}
\citation{nymi}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Overview}{1}}
\newlabel{sec:background}{{2}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Background on Authenticating Wearable Devices}{1}}
\citation{stevenage1999visual}
\citation{okumura2006study}
\citation{monrose2000keystroke}
\citation{jorgensen2011mouse}
\citation{bo2013silentsense}
\citation{de2012touch}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  These plots show the raw accelerometer data in the time domain for five different users when they move their head in response to a music track wearing the same Google glass. The plots indicate that different users' head movement patterns appear distinctive from each other. The five users wore a Google Glass (in turns) and listened to a 10 second audio snapshot of a pop song.}}{2}}
\newlabel{fig:raw}{{1}{2}}
\citation{jain2004introduction}
\citation{zentner2010rhythmic}
\citation{googleglass}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of Headbanger. The head-worn device authenticates the right user based on signatures generated from head-movement patterns in response to an audio snapshot played on the device.}}{3}}
\newlabel{fig:illustrate}{{2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Body Movement as a Behavioral Biometric}{3}}
\newlabel{subsec:headmovements}{{2.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Overview of \nobreakspace  {}{\em  Headbanger}}{3}}
\citation{challis1983design}
\citation{***}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Research Challenges}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Establishing Body Movement Patterns as Behavioral Biometrics}{4}}
\newlabel{sec:learning}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preliminary Results}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces In this set of experiments, we studied whether a user can successfully repeat her own head-movement pattern. We had 8 subjects, each performing her own choice of head-movement patterns. We collected 38 samples for each subject. (a) shows the FRR and FAR results for each subject, and (b) shows the BAC results. Thresholding-based classification with top 3 voting was used to generate these results. }}{5}}
\newlabel{fig:exp2_frr_far_bac}{{3}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average FAR, FRR, and BAC for SVM-based classification when we choose different 4 imitators in the training set (from the total 15 imitators). We have the results for different sample durations. In these results, we use the earliest 40 owner samples in the training set.}}{5}}
\newlabel{tab:kfoldfalse-svm}{{1}{5}}
\citation{hernandezbioglass}
\citation{nymi}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Proposed Research}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Authentication Accuracy}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Reliability}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Multi-Modality}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}hand movements}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Building the Body Movement Based Authentication System}{6}}
\newlabel{sec:system}{{4}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Preliminary Work}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The software modules for the Headbanger authentication app we implemented in the preliminary study. Note that the Training Set Construction Module is executed on the bluetooth-paired smartphone because it is the most computing intensive module. }}{7}}
\newlabel{fig:software_arch}{{4}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Measured processing latencies on Google Glass with different sample durations. We generated the results using Top 1 testing for thresholding based classification.}}{7}}
\newlabel{tab:glass}{{2}{7}}
\bibstyle{plain}
\bibdata{../mobisys_paper/sugang}
\bibcite{fitbit}{1}
\bibcite{googleglass}{2}
\bibcite{nymi}{3}
\bibcite{smartwatch}{4}
\bibcite{ailisto2006soft}{5}
\bibcite{bo2013silentsense}{6}
\bibcite{challis1983design}{7}
\bibcite{collins2002silhouette}{8}
\bibcite{cornelius2014wearable}{9}
\bibcite{de2012touch}{10}
\bibcite{hernandezbioglass}{11}
\bibcite{jain2004introduction}{12}
\bibcite{jorgensen2011mouse}{13}
\bibcite{mann1997wearable}{14}
\bibcite{monrose2000keystroke}{15}
\bibcite{o2003comparing}{16}
\bibcite{okumura2006study}{17}
\bibcite{rahman2014bodybeat}{18}
\bibcite{stevenage1999visual}{19}
\bibcite{yampolskiy2007motor}{20}
\bibcite{zentner2010rhythmic}{21}
