\relax 
\citation{mann1997wearable}
\citation{googleglass}
\citation{smartwatch}
\citation{fitbit}
\citation{fitbit}
\citation{smartwatch}
\citation{googleglass}
\citation{fitbit}
\citation{rahman2014bodybeat}
\citation{cornelius2014wearable}
\citation{stevenage1999visual}
\citation{okumura2006study}
\citation{monrose2000keystroke}
\citation{jorgensen2011mouse}
\citation{bo2013silentsense}
\citation{de2012touch}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\newlabel{sec:intro}{{1}{1}}
\citation{jain2004introduction}
\citation{o2003comparing}
\citation{yampolskiy2007motor}
\citation{wu1997measure}
\citation{yan2007biometric}
\citation{zhao1998discriminant}
\citation{hong1998fingerprint}
\citation{wildes1997iris}
\citation{yan2007biometric}
\citation{baldisserra2005fake}
\citation{hill2002retina}
\citation{markowitz2000voice}
\citation{reynolds2000speaker}
\citation{bowyer2006survey}
\citation{biddle2012graphical}
\citation{sherman2014user}
\citation{jain1997identity}
\citation{collins2002silhouette}
\citation{ailisto2006soft}
\citation{nymi}
\citation{stevenage1999visual}
\citation{okumura2006study}
\citation{monrose2000keystroke}
\citation{jorgensen2011mouse}
\citation{bo2013silentsense}
\citation{de2012touch}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background and Overview}{2}}
\newlabel{sec:background}{{2}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Background on Behavioral Biometrics}{2}}
\citation{jain2004introduction}
\citation{zentner2010rhythmic}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  These plots show the raw accelerometer data in the time domain for five different users when they move their head in response to a music track wearing the same Google glass. The plots indicate that different users' head movement patterns appear distinctive from each other. The five users wore a Google Glass (in turns) and listened to a 10 second audio snapshot of a pop song.}}{3}}
\newlabel{fig:raw}{{1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Body Movement as a Behavioral Biometric}{3}}
\newlabel{subsec:headmovements}{{2.2}{3}}
\citation{harwin1990analysis}
\citation{westeyn2004recognizing}
\citation{ishimaru2014blink}
\citation{ailisto2005identifying}
\citation{gafurov2007gait}
\citation{okumura2006study}
\citation{gafurov2008arm}
\citation{gafurov2006biometric}
\citation{karantonis2006implementation}
\citation{mantyjarvi2005identifying}
\citation{derawi2010unobtrusive}
\citation{gafurov2011user}
\citation{sae2012biometric}
\citation{frank2013touchalytics}
\citation{cai2013mobile}
\citation{feng2014tips}
\citation{liu2009uwave}
\citation{shahzad2013secure}
\citation{googleglass}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Overview of \nobreakspace  {}{\em  Headbanger}}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of Headbanger. The head-worn device authenticates the right user based on signatures generated from head-movement patterns in response to an audio snapshot played on the device.}}{5}}
\newlabel{fig:illustrate}{{2}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Research Challenges}{5}}
\citation{challis1983design}
\citation{dtw}
\@writefile{toc}{\contentsline {section}{\numberline {3}Challenge I: Establishing Body Movement Patterns as Reliable Features for Authentication}{6}}
\newlabel{sec:learning}{{3}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Preliminary Results}{6}}
\citation{palmerini2011feature}
\citation{Pirttikangas2006feature}
\citation{preece2009comparison}
\citation{bao2004activity}
\citation{zhang2011feature}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces In this set of experiments, we studied whether a user can successfully repeat her own head-movement pattern. We had 8 subjects, each performing her own choice of head-movement patterns. We collected 38 samples for each subject. (a) shows the FRR and FAR results for each subject, and (b) shows the BAC results.}}{7}}
\newlabel{fig:exp2_frr_far_bac}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Proposed Research}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Average FAR, FRR, and BAC for SVM-based classification in our preliminary study. The results show that even for the simplest nodding, we can correctly authenticate 95\% of the users when the samples are longer than 6 seconds. }}{7}}
\newlabel{tab:kfoldfalse-svm}{{1}{7}}
\citation{bartenieff1980body}
\citation{brass2001movement}
\citation{dassonville2001effect}
\citation{hernandezbioglass}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Feature Selection and Information Entropy}{8}}
\newlabel{sec:feature}{{3.2.1}{8}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}User Authentication Through Combined Movements and Sensors}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  A person's blinking patterns (measured by the infrared proximity sensor on the Google Glass) with respect to music beats are also differentiable.}}{8}}
\newlabel{fig:blink}{{4}{8}}
\citation{mayagoitia2002accelerometer}
\citation{jovanov2005wireless}
\citation{li2009accurate}
\citation{zhu2004real}
\citation{williamson2001detecting}
\citation{sabatini2005assessment}
\citation{euston2008complementary}
\citation{mayrhofer2007shake}
\citation{patel2004gesture}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.3}Robust Authentication in Mobile Settings}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Walking (a) usually has more energy than music-stimulated partial body movement such as nodding (b).}}{9}}
\newlabel{fig:walk}{{5}{9}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.4}Stronger Authentication Through Body Movement Based Passwords}{10}}
\newlabel{subsec:password}{{3.2.4}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Challenge II: Building an Efficient Body Movement Based Authentication System}{10}}
\newlabel{sec:system}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Preliminary Work}{10}}
\citation{dollar2005behavior}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The software modules for the Headbanger authentication app we implemented in the preliminary study. }}{11}}
\newlabel{fig:software_arch}{{6}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Measured processing latencies on Google Glass with different sample durations. In this set of experiments, we tried to understand the processing capability constraints and didn't optimize the code. }}{11}}
\newlabel{tab:glass}{{7}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Proposed Research}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces  The benefit of pipelined authentication: (a) shows the original latency to collect and process a 10-second sample (numbers taken from Figure\nobreakspace  {}7\hbox {}, (b) shows the much reduced latency by breaking the 10-second signal to five 2-second chunks and pipeline the collection and processing procedures, and (c) shows that the delay can be further reduced if using a portion of the signal can correctly infer the classification result.}}{12}}
\newlabel{fig:pipeline}{{8}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation Plan}{13}}
\newlabel{sec:eval}{{5}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Developing\nobreakspace  {}{\em  Headbanger}\nobreakspace  {}App on Google Glass and Moto 360}{13}}
\newlabel{subsec:app}{{5.1}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  We will implement\nobreakspace  {}{\em  Headbanger}\nobreakspace  {}on (a) Google Glass and (b) Moto 360 smart watch.}}{13}}
\newlabel{fig:devices}{{9}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Data Collection}{13}}
\newlabel{subsec:user}{{5.2}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Our team member was collecting data with one of the participants in the preliminary study. }}{13}}
\newlabel{fig:exp}{{10}{13}}
\citation{nymi}
\citation{scheirer1999expression}
\citation{di2005magic}
\citation{choudhury2002sociometer}
\citation{meyerhoff1993line}
\citation{starner2000gesture}
\citation{farringdon1999wearable}
\citation{led2004design}
\citation{hung2004wearable}
\citation{mistry2009sixthsense}
\citation{giansanti2008assessment}
\citation{jsspp03}
\citation{sensorfusion05}
\citation{xu:wise04}
\citation{xu:mobihoc05}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The detailed 3-year work plan.}}{14}}
\newlabel{fig:plan}{{11}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Long Term App Deployment and Evaluation}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Work Plan}{14}}
\newlabel{subsec:plan}{{5.4}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Curriculum Development Activities and Broader Impact}{14}}
\newlabel{sec:education}{{6}{14}}
\citation{zan-etal:mdm10}
\citation{sun2012association}
\citation{sun2011improved}
\citation{sun2012boomerang}
\citation{moore2013building}
\citation{xu2012improving}
\citation{xu2012towards}
\citation{xu2013crowd++}
\citation{xu2013scpl}
\citation{bhanage2011virtual}
\citation{bhanage2011experimental}
\citation{vu2012dmap}
\citation{sun2011improving}
\citation{zhang2012content}
\citation{liu2013secure}
\citation{zhang2013using}
\citation{li2013mobile}
\citation{li2012popularity}
\citation{nsf-ct-anonymity}
\citation{1315266_hoh_privacy_gps}
\citation{hoh06:_enhan_privac_preser_anony_locat}
\citation{hoh_virtual_trip_lines}
\citation{1717364_hoh_privacy_traffic_monitoring}
\@writefile{toc}{\contentsline {section}{\numberline {7}Results from Prior NSF Projects}{15}}
\newlabel{sec:prior}{{7}{15}}
\bibstyle{plain}
\bibdata{../mobisys_paper/sugang,yyzhang,MG_prior}
\bibcite{fitbit}{1}
\bibcite{googleglass}{2}
\bibcite{nymi}{3}
\bibcite{smartwatch}{4}
\bibcite{ailisto2006soft}{5}
\bibcite{ailisto2005identifying}{6}
\bibcite{baldisserra2005fake}{7}
\bibcite{bao2004activity}{8}
\bibcite{bartenieff1980body}{9}
\bibcite{dtw}{10}
\bibcite{bhanage2011experimental}{11}
\bibcite{bhanage2011virtual}{12}
\bibcite{biddle2012graphical}{13}
\bibcite{bo2013silentsense}{14}
\bibcite{bowyer2006survey}{15}
\bibcite{brass2001movement}{16}
\bibcite{cai2013mobile}{17}
\bibcite{challis1983design}{18}
\bibcite{choudhury2002sociometer}{19}
\bibcite{collins2002silhouette}{20}
\bibcite{cornelius2014wearable}{21}
\bibcite{dassonville2001effect}{22}
\bibcite{de2012touch}{23}
\bibcite{derawi2010unobtrusive}{24}
\bibcite{di2005magic}{25}
\bibcite{dollar2005behavior}{26}
\bibcite{euston2008complementary}{27}
\bibcite{farringdon1999wearable}{28}
\bibcite{feng2014tips}{29}
\bibcite{frank2013touchalytics}{30}
\bibcite{gafurov2011user}{31}
\bibcite{gafurov2006biometric}{32}
\bibcite{gafurov2007gait}{33}
\bibcite{gafurov2008arm}{34}
\bibcite{giansanti2008assessment}{35}
\bibcite{nsf-ct-anonymity}{36}
\bibcite{harwin1990analysis}{37}
\bibcite{hernandezbioglass}{38}
\bibcite{hill2002retina}{39}
\bibcite{1717364_hoh_privacy_traffic_monitoring}{40}
\bibcite{hoh_virtual_trip_lines}{41}
\bibcite{1315266_hoh_privacy_gps}{42}
\bibcite{hoh06:_enhan_privac_preser_anony_locat}{43}
\bibcite{hong1998fingerprint}{44}
\bibcite{hung2004wearable}{45}
\bibcite{ishimaru2014blink}{46}
\bibcite{jain1997identity}{47}
\bibcite{jain2004introduction}{48}
\bibcite{jorgensen2011mouse}{49}
\bibcite{jovanov2005wireless}{50}
\bibcite{karantonis2006implementation}{51}
\bibcite{led2004design}{52}
\bibcite{li2012popularity}{53}
\bibcite{li2013mobile}{54}
\bibcite{li2009accurate}{55}
\bibcite{liu2009uwave}{56}
\bibcite{liu2013secure}{57}
\bibcite{mann1997wearable}{58}
\bibcite{mantyjarvi2005identifying}{59}
\bibcite{markowitz2000voice}{60}
\bibcite{mayagoitia2002accelerometer}{61}
\bibcite{mayrhofer2007shake}{62}
\bibcite{meyerhoff1993line}{63}
\bibcite{mistry2009sixthsense}{64}
\bibcite{monrose2000keystroke}{65}
\bibcite{moore2013building}{66}
\bibcite{o2003comparing}{67}
\bibcite{okumura2006study}{68}
\bibcite{palmerini2011feature}{69}
\bibcite{patel2004gesture}{70}
\bibcite{Pirttikangas2006feature}{71}
\bibcite{preece2009comparison}{72}
\bibcite{rahman2014bodybeat}{73}
\bibcite{reynolds2000speaker}{74}
\bibcite{sabatini2005assessment}{75}
\bibcite{sae2012biometric}{76}
\bibcite{scheirer1999expression}{77}
\bibcite{shahzad2013secure}{78}
\bibcite{sherman2014user}{79}
\bibcite{starner2000gesture}{80}
\bibcite{stevenage1999visual}{81}
\bibcite{sun2011improved}{82}
\bibcite{sun2012boomerang}{83}
\bibcite{sun2011improving}{84}
\bibcite{sun2012association}{85}
\bibcite{vu2012dmap}{86}
\bibcite{westeyn2004recognizing}{87}
\bibcite{wildes1997iris}{88}
\bibcite{williamson2001detecting}{89}
\bibcite{wu1997measure}{90}
\bibcite{xu2013scpl}{91}
\bibcite{xu2012improving}{92}
\bibcite{xu2012towards}{93}
\bibcite{xu2013crowd++}{94}
\bibcite{xu:mobihoc05}{95}
\bibcite{xu:wise04}{96}
\bibcite{yampolskiy2007motor}{97}
\bibcite{yan2007biometric}{98}
\bibcite{sensorfusion05}{99}
\bibcite{zan-etal:mdm10}{100}
\bibcite{zentner2010rhythmic}{101}
\bibcite{zhang2012content}{102}
\bibcite{zhang2013using}{103}
\bibcite{zhang2011feature}{104}
\bibcite{jsspp03}{105}
\bibcite{zhao1998discriminant}{106}
\bibcite{zhu2004real}{107}
